{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "1.0\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialize CNN model\n",
    "classifier = Sequential()\n",
    "\n",
    "# Layer-1 Convolution\n",
    "classifier.add(Conv2D(32,(3,3), input_shape = (64,64,3), activation = 'relu'))\n",
    "\n",
    "# Layer-2 Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Layer-3 Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Layer-4 Full Connection\n",
    "classifier.add(Dense(units = 128, activation = \"relu\"))\n",
    "classifier.add(Dense(units = 1, activation = \"sigmoid\"))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set', target_size = (64, 64), batch_size = 32, class_mode = 'binary')\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "# classifier.fit_generator(training_set, steps_per_epoch = 8000, epochs = 10, validation_data = test_set, validation_steps = 800)\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('cat.1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "# training_set.class_indices\n",
    "print(result[0][0])\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "(array([[[[0.80021584, 0.5149756 , 0.20784315],\n",
      "         [0.8002457 , 0.515013  , 0.20784315],\n",
      "         [0.8002756 , 0.51505035, 0.20784315],\n",
      "         ...,\n",
      "         [0.68352944, 0.38007846, 0.17239217],\n",
      "         [0.6834174 , 0.37995893, 0.1723324 ],\n",
      "         [0.6833053 , 0.37983936, 0.17227262]],\n",
      "\n",
      "        [[0.81303084, 0.5287788 , 0.2160727 ],\n",
      "         [0.8130458 , 0.5287713 , 0.21616983],\n",
      "         [0.81306076, 0.52876383, 0.216267  ],\n",
      "         ...,\n",
      "         [0.6666592 , 0.3640435 , 0.1572968 ],\n",
      "         [0.6667937 , 0.3642004 , 0.1573267 ],\n",
      "         [0.6669282 , 0.36435735, 0.15735659]],\n",
      "\n",
      "        [[0.8182174 , 0.52433145, 0.25604254],\n",
      "         [0.8181726 , 0.52429414, 0.25595284],\n",
      "         [0.81812775, 0.5242567 , 0.25586316],\n",
      "         ...,\n",
      "         [0.7217728 , 0.4276551 , 0.17137791],\n",
      "         [0.7218176 , 0.42769995, 0.1714078 ],\n",
      "         [0.7218625 , 0.4277448 , 0.17143771]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.23077706, 0.29735866, 0.27425462],\n",
      "         [0.23072474, 0.29729888, 0.27423218],\n",
      "         [0.23067243, 0.29723907, 0.27420977],\n",
      "         ...,\n",
      "         [0.53238654, 0.2784314 , 0.21541542],\n",
      "         [0.5323193 , 0.2784314 , 0.2153033 ],\n",
      "         [0.532252  , 0.2784314 , 0.21519122]],\n",
      "\n",
      "        [[0.20613511, 0.26919642, 0.26369375],\n",
      "         [0.20608279, 0.26913664, 0.26367134],\n",
      "         [0.20603047, 0.26907685, 0.26364893],\n",
      "         ...,\n",
      "         [0.50182116, 0.27829176, 0.16484554],\n",
      "         [0.5018137 , 0.27828428, 0.164853  ],\n",
      "         [0.5018062 , 0.2782768 , 0.16486049]],\n",
      "\n",
      "        [[0.14945254, 0.20258544, 0.22109231],\n",
      "         [0.14932548, 0.20243599, 0.22099516],\n",
      "         [0.14919844, 0.20228653, 0.220898  ],\n",
      "         ...,\n",
      "         [0.49830088, 0.27477145, 0.16836582],\n",
      "         [0.4982934 , 0.27476397, 0.16837329],\n",
      "         [0.49828592, 0.2747565 , 0.16838077]]],\n",
      "\n",
      "\n",
      "       [[[0.01661046, 0.01661046, 0.01661046],\n",
      "         [0.016686  , 0.016686  , 0.016686  ],\n",
      "         [0.01676153, 0.01676153, 0.01676153],\n",
      "         ...,\n",
      "         [0.09349865, 0.09349865, 0.09349865],\n",
      "         [0.09356159, 0.09356159, 0.09356159],\n",
      "         [0.09362453, 0.09362453, 0.09362453]],\n",
      "\n",
      "        [[0.03137255, 0.03137255, 0.03137255],\n",
      "         [0.03137255, 0.03137255, 0.03137255],\n",
      "         [0.03137255, 0.03137255, 0.03137255],\n",
      "         ...,\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079],\n",
      "         [0.10196079, 0.10196079, 0.10196079]],\n",
      "\n",
      "        [[0.03137255, 0.03137255, 0.03137255],\n",
      "         [0.03137255, 0.03137255, 0.03137255],\n",
      "         [0.03137255, 0.03137255, 0.03137255],\n",
      "         ...,\n",
      "         [0.11030114, 0.11030114, 0.11030114],\n",
      "         [0.11037668, 0.11037668, 0.11037668],\n",
      "         [0.11045221, 0.11045221, 0.11045221]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.43411726, 0.43411726, 0.43411726],\n",
      "         [0.43430611, 0.43430611, 0.43430611],\n",
      "         [0.43449494, 0.43449494, 0.43449494],\n",
      "         ...,\n",
      "         [0.48560822, 0.49345136, 0.4895298 ],\n",
      "         [0.48555785, 0.493401  , 0.48947942],\n",
      "         [0.48550746, 0.4933506 , 0.48942903]],\n",
      "\n",
      "        [[0.44893867, 0.44893867, 0.44893867],\n",
      "         [0.44896382, 0.44896382, 0.44896382],\n",
      "         [0.44898903, 0.44898903, 0.44898903],\n",
      "         ...,\n",
      "         [0.47160006, 0.47944322, 0.47552165],\n",
      "         [0.47154972, 0.47939286, 0.4754713 ],\n",
      "         [0.47149935, 0.4793425 , 0.47542092]],\n",
      "\n",
      "        [[0.4261689 , 0.4261689 , 0.4261689 ],\n",
      "         [0.42604297, 0.42604297, 0.42604297],\n",
      "         [0.42591712, 0.42591712, 0.42591712],\n",
      "         ...,\n",
      "         [0.5160753 , 0.52391845, 0.4777589 ],\n",
      "         [0.51625156, 0.5240947 , 0.4777715 ],\n",
      "         [0.51642776, 0.5242709 , 0.47778407]]]], dtype=float32), array([0., 0.], dtype=float32))\n",
      "(array([[[[0.16470589, 0.14901961, 0.13725491],\n",
      "         [0.16470589, 0.14901961, 0.13725491],\n",
      "         [0.16470589, 0.14901961, 0.13725491],\n",
      "         ...,\n",
      "         [0.23529413, 0.21960786, 0.21568629],\n",
      "         [0.23529413, 0.21960786, 0.21568629],\n",
      "         [0.23529413, 0.21960786, 0.21568629]],\n",
      "\n",
      "        [[0.16470589, 0.14901961, 0.13725491],\n",
      "         [0.16470589, 0.14901961, 0.13725491],\n",
      "         [0.16470589, 0.14901961, 0.13725491],\n",
      "         ...,\n",
      "         [0.23529413, 0.21960786, 0.21568629],\n",
      "         [0.23529413, 0.21960786, 0.21568629],\n",
      "         [0.23529413, 0.21960786, 0.21568629]],\n",
      "\n",
      "        [[0.163929  , 0.14798376, 0.13596009],\n",
      "         [0.16397297, 0.1480424 , 0.1360334 ],\n",
      "         [0.16401698, 0.14810105, 0.13610671],\n",
      "         ...,\n",
      "         [0.23529413, 0.21960786, 0.21568629],\n",
      "         [0.23529413, 0.21960786, 0.21568629],\n",
      "         [0.23529413, 0.21960786, 0.21568629]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3529412 , 0.3529412 , 0.20392159],\n",
      "         [0.3529412 , 0.3529412 , 0.20392159],\n",
      "         [0.3529412 , 0.3529412 , 0.20392159],\n",
      "         ...,\n",
      "         [0.2599321 , 0.23102334, 0.161164  ],\n",
      "         [0.25963885, 0.23070076, 0.16085607],\n",
      "         [0.25934556, 0.23037815, 0.16054812]],\n",
      "\n",
      "        [[0.3529412 , 0.3529412 , 0.20392159],\n",
      "         [0.3529412 , 0.3529412 , 0.20392159],\n",
      "         [0.3529412 , 0.3529412 , 0.20392159],\n",
      "         ...,\n",
      "         [0.27450982, 0.24705884, 0.1764706 ],\n",
      "         [0.27450982, 0.24705884, 0.1764706 ],\n",
      "         [0.27450982, 0.24705884, 0.1764706 ]],\n",
      "\n",
      "        [[0.3529412 , 0.3529412 , 0.20392159],\n",
      "         [0.3529412 , 0.3529412 , 0.20392159],\n",
      "         [0.3529412 , 0.3529412 , 0.20392159],\n",
      "         ...,\n",
      "         [0.27450982, 0.24705884, 0.1764706 ],\n",
      "         [0.27450982, 0.24705884, 0.1764706 ],\n",
      "         [0.27450982, 0.24705884, 0.1764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.16078432, 0.16862746],\n",
      "         [0.12941177, 0.16078432, 0.16862746],\n",
      "         [0.12941177, 0.16078432, 0.16862746],\n",
      "         ...,\n",
      "         [0.6313726 , 0.2509804 , 0.        ],\n",
      "         [0.6313726 , 0.2509804 , 0.        ],\n",
      "         [0.6313726 , 0.2509804 , 0.        ]],\n",
      "\n",
      "        [[0.12941177, 0.16078432, 0.16862746],\n",
      "         [0.12941177, 0.16078432, 0.16862746],\n",
      "         [0.12941177, 0.16078432, 0.16862746],\n",
      "         ...,\n",
      "         [0.6313726 , 0.2509804 , 0.        ],\n",
      "         [0.6313726 , 0.2509804 , 0.        ],\n",
      "         [0.6313726 , 0.2509804 , 0.        ]],\n",
      "\n",
      "        [[0.12941177, 0.16078432, 0.16862746],\n",
      "         [0.12941177, 0.16078432, 0.16862746],\n",
      "         [0.12941177, 0.16078432, 0.16862746],\n",
      "         ...,\n",
      "         [0.6313726 , 0.2509804 , 0.        ],\n",
      "         [0.6313726 , 0.2509804 , 0.        ],\n",
      "         [0.6313726 , 0.2509804 , 0.        ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.87843144, 0.48235297, 0.21568629],\n",
      "         [0.87843144, 0.48235297, 0.21568629],\n",
      "         [0.87843144, 0.48235297, 0.21568629],\n",
      "         ...,\n",
      "         [0.83921576, 0.38431376, 0.05882353],\n",
      "         [0.83921576, 0.38431376, 0.05882353],\n",
      "         [0.83921576, 0.38431376, 0.05882353]],\n",
      "\n",
      "        [[0.87843144, 0.48235297, 0.21568629],\n",
      "         [0.87843144, 0.48235297, 0.21568629],\n",
      "         [0.87843144, 0.48235297, 0.21568629],\n",
      "         ...,\n",
      "         [0.83921576, 0.38431376, 0.05882353],\n",
      "         [0.83921576, 0.38431376, 0.05882353],\n",
      "         [0.83921576, 0.38431376, 0.05882353]],\n",
      "\n",
      "        [[0.87843144, 0.48235297, 0.21568629],\n",
      "         [0.87843144, 0.48235297, 0.21568629],\n",
      "         [0.87843144, 0.48235297, 0.21568629],\n",
      "         ...,\n",
      "         [0.83921576, 0.38431376, 0.05882353],\n",
      "         [0.83921576, 0.38431376, 0.05882353],\n",
      "         [0.83921576, 0.38431376, 0.05882353]]]], dtype=float32), array([1., 1.], dtype=float32))\n",
      "(array([[[[0.07370656, 0.12901016, 0.03906794],\n",
      "         [0.0737022 , 0.12900797, 0.0390565 ],\n",
      "         [0.07369784, 0.12900579, 0.03904507],\n",
      "         ...,\n",
      "         [0.0655977 , 0.1092259 , 0.08623097],\n",
      "         [0.06559334, 0.10921555, 0.0862228 ],\n",
      "         [0.06558898, 0.1092052 , 0.08621463]],\n",
      "\n",
      "        [[0.11674403, 0.17349735, 0.07789308],\n",
      "         [0.11675982, 0.17351152, 0.07791432],\n",
      "         [0.11677561, 0.17352566, 0.07793555],\n",
      "         ...,\n",
      "         [0.1058032 , 0.11511929, 0.10349396],\n",
      "         [0.1058179 , 0.11513018, 0.10350595],\n",
      "         [0.10583261, 0.11514107, 0.10351792]],\n",
      "\n",
      "        [[0.15708242, 0.20806281, 0.13747458],\n",
      "         [0.15707807, 0.20805846, 0.13747023],\n",
      "         [0.15707372, 0.20805411, 0.13746586],\n",
      "         ...,\n",
      "         [0.11556537, 0.11557689, 0.119533  ],\n",
      "         [0.11555394, 0.11556654, 0.11952592],\n",
      "         [0.1155425 , 0.1155562 , 0.11951885]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.34643418, 0.49055535, 0.17351174],\n",
      "         [0.34644887, 0.4905657 , 0.17353351],\n",
      "         [0.34646356, 0.49057606, 0.1735553 ],\n",
      "         ...,\n",
      "         [0.24967942, 0.38033378, 0.09823304],\n",
      "         [0.24966799, 0.3803267 , 0.09821998],\n",
      "         [0.24965654, 0.38031963, 0.09820691]],\n",
      "\n",
      "        [[0.3900216 , 0.5032817 , 0.2834001 ],\n",
      "         [0.39001992, 0.5032757 , 0.28340992],\n",
      "         [0.3900183 , 0.50326973, 0.2834197 ],\n",
      "         ...,\n",
      "         [0.31232128, 0.42663673, 0.1328846 ],\n",
      "         [0.31234798, 0.4266552 , 0.1329053 ],\n",
      "         [0.31237465, 0.42667374, 0.13292599]],\n",
      "\n",
      "        [[0.33934814, 0.47257784, 0.23553593],\n",
      "         [0.3393356 , 0.4725751 , 0.23551308],\n",
      "         [0.33932307, 0.4725724 , 0.2354902 ],\n",
      "         ...,\n",
      "         [0.38205093, 0.4663372 , 0.21187454],\n",
      "         [0.38204494, 0.46633068, 0.21187674],\n",
      "         [0.38203892, 0.46632412, 0.21187891]]],\n",
      "\n",
      "\n",
      "       [[[0.88414997, 0.87630683, 0.88807154],\n",
      "         [0.88184965, 0.8740065 , 0.8857712 ],\n",
      "         [0.86992186, 0.8620787 , 0.87384343],\n",
      "         ...,\n",
      "         [0.7219677 , 0.6945167 , 0.67098725],\n",
      "         [0.7190841 , 0.6905346 , 0.67076164],\n",
      "         [0.7230759 , 0.68887824, 0.6884195 ]],\n",
      "\n",
      "        [[0.8891892 , 0.88134605, 0.89311075],\n",
      "         [0.90963   , 0.90178686, 0.91355157],\n",
      "         [0.8811467 , 0.8733036 , 0.8850683 ],\n",
      "         ...,\n",
      "         [0.72252864, 0.69507766, 0.67154825],\n",
      "         [0.71520084, 0.6872247 , 0.6652708 ],\n",
      "         [0.7358373 , 0.7051609 , 0.6913075 ]],\n",
      "\n",
      "        [[0.8903771 , 0.88253397, 0.8942987 ],\n",
      "         [0.92748684, 0.9196437 , 0.9314084 ],\n",
      "         [0.8917929 , 0.88394976, 0.89571446],\n",
      "         ...,\n",
      "         [0.7201792 , 0.69232935, 0.67040163],\n",
      "         [0.72020805, 0.6928535 , 0.6689241 ],\n",
      "         [0.72880465, 0.7019458 , 0.67900765]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.65498877, 0.58522594, 0.53177845],\n",
      "         [0.6221366 , 0.58700836, 0.5706761 ],\n",
      "         [0.7861917 , 0.7964217 , 0.8214108 ],\n",
      "         ...,\n",
      "         [0.8531495 , 0.85146034, 0.81943154],\n",
      "         [0.8486489 , 0.8198728 , 0.8037238 ],\n",
      "         [0.683114  , 0.60978204, 0.61608034]],\n",
      "\n",
      "        [[0.52929693, 0.45747346, 0.39749995],\n",
      "         [0.5562656 , 0.5138965 , 0.48922256],\n",
      "         [0.74407625, 0.7441369 , 0.7523088 ],\n",
      "         ...,\n",
      "         [0.85398614, 0.83045673, 0.83045673],\n",
      "         [0.88278544, 0.8567926 , 0.8562421 ],\n",
      "         [0.951005  , 0.9123465 , 0.90896595]],\n",
      "\n",
      "        [[0.6638014 , 0.5990304 , 0.5508392 ],\n",
      "         [0.59222156, 0.556322  , 0.53928363],\n",
      "         [0.71226674, 0.71584886, 0.73458475],\n",
      "         ...,\n",
      "         [0.9160848 , 0.8925554 , 0.8925554 ],\n",
      "         [0.8435094 , 0.8203833 , 0.82269955],\n",
      "         [0.8910928 , 0.8700412 , 0.88426745]]]], dtype=float32), array([1., 0.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip=True)\n",
    "\n",
    "i = 0\n",
    "for batch in train_data.flow_from_directory('dataset/training_set', target_size = (64,64), batch_size = 2, class_mode = 'binary', save_to_dir = 'processed_dataset/training_set_binary'):\n",
    "    i += 1\n",
    "    print(batch)\n",
    "    if i > 2:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
